# Chatbot-Response-Acceleration-with-CUDA-LLM-Inference

## Optimized the speed of chatbot responses by using CUDA to accelerate the inference of a language model. This allowed for faster customer service interactions on local servers.
